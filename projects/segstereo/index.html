<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<html>

<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <link href="main.css" rel="stylesheet" media="all">
    <meta name="description" content="SegStereo: Exploiting Semantic Information for Disparity Estimation" />
    <meta name="keywords" content="Disparity Estimation, Semantic Cues, Semantic Feature Embedding, Softmax Loss Regularization">
    <script>
    function buttonSwitch(id, text) {
        old_src = document.getElementById(id).src;
        ind = old_src.lastIndexOf('/');
        document.getElementById(id).src = old_src.substr(0, ind + 1) + text;
    }
    </script>
    <title>SegStereo: Exploiting Semantic Information for Disparity Estimation</title>
</head>

<body>
    <div id="top_arrow" style="position: fixed; bottom: 10px; right: 10px;">
        <a href="#title">
<img src="./figures/top_arrow.jpg" style="border: 0pt none ; width: 26px; height: 32px;"/></a>
    </div>
    <h2 id="title" class="auto-style1">SegStereo: Exploiting Semantic Information for Disparity Estimation</h2>
    <p class="auto-style7" align="center">
    	<a href="https://scholar.google.com/citations?user=6RaR1cQAAAAJ&hl=zh-CN" target="_blank">Guorun Yang</a><sup>1*</sup>&nbsp;&nbsp;&nbsp;
        <a href="https://hszhao.github.io" target="_blank">Hengshuang Zhao</a><sup>2*</sup>&nbsp;&nbsp;&nbsp;
        <a href="http://shijianping.me" target="_blank">Jianping Shi</a><sup>3</sup>&nbsp;&nbsp;&nbsp;
        <a href="http://www.tsinghua.edu.cn/publish/csen/4623/2010/20101224173318337163808/20101224173318337163808_.html" target="_blank">Zhidong Deng</a><sup>1</sup>&nbsp;&nbsp;&nbsp;
        <a href="http://www.cse.cuhk.edu.hk/leojia" target="_blank">Jiaya Jia</a><sup>2,4</sup>&nbsp;&nbsp;&nbsp;
    </p>
    <p class="auto-style7" align="center">
        <sup>1</sup> Tsinghua Univeristy&nbsp;&nbsp;&nbsp;&nbsp;
        <sup>2</sup> The Chinese Univeristy of Hong Kong&nbsp;&nbsp;&nbsp;&nbsp;
        <sup>3</sup> SenseTime Research&nbsp;&nbsp;&nbsp;&nbsp;
        <sup>4</sup> Tencent Youtu Lab&nbsp;&nbsp;&nbsp;&nbsp;
        <br>[* indicates equal contribution]
    </p>
    <p align="center">
        <table style="width:960px" align="center">
            <tr>
                <td><img width=960px alt="" src="figures/segstereo.png"></td>
            </tr>
            <tr>
                <td>
                    <p class="auto-style5" align="justify">Our SegStereo framework. We extract intermediate features F_l and F_r from stereo input. We calculate the cost volume F_c via the correlation operator. The left segmentation feature map F_s^l is aggregated into disparity branch as semantic feature embedding. The right segmentation feature map F_s^r is warped to left view for per-pixel semantic prediction with softmax loss regularization. Both steps incorporate semantic information to improve disparity estimation. The SegStereo framework enables both unsupervised and supervised learning, using photometric loss L_p or disparity regression loss L_r.</p>
                </td>
            </tr>
        </table>
        <p class="auto-style4"><strong>Abstract</span></strong></p>
        <p class="auto-style5">Disparity estimation for binocular stereo images finds a wide range of applications. Traditional algorithms may fail on featureless regions, which could be handled by high-level clues such as semantic segments. In this paper, we suggest that appropriate incorporation of semantic cues can greatly rectify prediction in commonly-used disparity estimation frameworks. Our method conducts semantic feature embedding and regularizes semantic cues as the loss term to improve learning disparity. Our unified model SegStereo employs semantic features from segmentation and introduces semantic softmax loss, which helps improve the prediction accuracy of disparity maps. The semantic cues work well in both unsupervised and supervised manners. SegStereo achieves state-of-the-art results on KITTI Stereo benchmark and produces decent prediction on both CityScapes and FlyingThings3D datasets.</p>
        <p class="auto-style4"><strong>Download</span></strong></p>
        <table cellSpacing=4 cellPadding=2 border=0 style="width: 90%">
            <tr COLSPAN="2">
                <td align="center" valign="center">
                    <img style="padding:0; clear:both; " src="figures/paper.png" align="middle" alt="Snapshot for paper" class="pdf" width="200" />
                </td>
                <td align="left" class="auto-style5">"SegStereo: Exploiting Semantic Information for Disparity Estimation&quot;
                    <br> Guorun Yang*, Hengshuang Zhao*, Jianping Shi, Zhidong Deng, Jiaya Jia.
                    <br>
                    <em>European Conference on Computer Vision</em> (<b>ECCV</b>), 2018.</br>
                    Top ranking performance in <a href="http://www.cvlibs.net/datasets/kitti/eval_stereo_flow.php?benchmark=stereo">KITTI Stereo Benchmark</a>.
                    <br>
                    <img alt="" height="32" src="figures/pdf.png">&nbsp;&nbsp;[<a href="../../papers/eccv18_segstereo.pdf">Paper</a>]&nbsp;&nbsp;[<a href="../../papers/eccv18_segstereo_supp.pdf">Supp</a>]&nbsp;&nbsp;[<a href="../../papers/eccv18_segstereo_bib.txt">Bib</a>]<br><br>
                    <img alt="" height="32" src="figures/github.png">&nbsp;&nbsp;[<a href="https://github.com/yangguorun/SegStereo">Code</a>]<br><br>
					<img alt="" height="32" src="figures/zip.png">&nbsp;&nbsp;[<a href="https://drive.google.com/file/d/1wPuC7DPkMDK0Ob4XEUXN-LIEBhG0-aRn/view?usp=sharing">Predictions-unsup_segstereo_kitti_ft]</a>]<br><br>
                </td>
            </tr>
        </table>

        <p class="auto-style4"><strong>Performance</span></strong></p>
        <table style="width:960px" align="center">
            <tr>
                <td><img width=450px alt="" src="figures/result1.png"></td>
                <td><img width=450px alt="" src="figures/result2.png"></td>
            </tr>
            <tr>
                <td><img width=450px alt="" src="figures/result3.png"></td>
                <td><img width=450px alt="" src="figures/result4.png"></td>
            </tr>
        </table>

        <p class="auto-style4"><strong>Visualization</span></strong></p>
        <table style="width:960px" align="center">
            <tr>
                <td><img width=960px alt="" src="figures/unsupervised_kitti2015.png"></td>
            </tr>
            <tr>
            	<td>
                    <p class="auto-style5">Qualitative examples of unsupervised SegStereo models on KITTI Stereo 2015 dataset. With the guidance of softmax regularization and additional fine-tune process, the accuracy of disparity is improved.</p>
                </td>
            </tr>
            <tr>
                <td><img width=960px alt="" src="figures/upsupervised_cityscapes.png"></td>
            </tr>
            <tr>
            	<td>
                    <p class="auto-style5">Qualitative examples of unsupervised-learning version of the SegStereo model on CityScapes validation set. From left to right: left input images, disparity maps predicted by SGM algorithm, and our disparity maps.</p>
                </td>
            </tr>
            <tr>
                <td><img width=960px alt="" src="figures/supervised_kitti2015.png"></td>
            </tr>
            <tr>
            	<td>
                    <p class="auto-style5">Supervised-learning results on KITTI Stereo 2015 test sets. By incorporating semantic information, our method is able to estimate accurate disparity. From left to right, we show left input images, disparity predictions of SegStereo, and error maps.</p>
                </td>
            </tr>
            <tr>
                <td><img width=960px alt="" src="figures/flyingthings3d.png"></td>
            </tr>
            <tr>
            	<td>
                    <p class="auto-style5">Qualitative examples of ResNetCorr and SegStereo model on FlyingThings3D validation set. From left to right, left images, ground-truth, ResNet-Corr results and SegStereo results.</p>
                </td>
            </tr>
        </table>
        <p align="center">[<a href="../../papers/eccv18_segstereo_supp.pdf">More Visualization</a>]</p>
        <p id="video" , class="auto-style4"><strong>Video</strong></p>
        <p class="auto-style5">Demo video processed by SegStereo on KITTI and Cityscapes datasets:</p>
        <iframe width="960" height="540" src="https://www.youtube.com/embed/bfrlFpJQHT8" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        <p class="auto-style1">
            <font color="#999999">Last update: Aug. 18, 2018</font>
        </p>
</body>

</html>